# 模块 4：AIBot 智搜系统实现细节

> 基于实际代码分析的技术路径详解

---

## 一、三层架构映射

### 1.1 流式处理架构与后端 LLM 对接

AIBot 系统采用 **Vercel AI SDK** 实现流式处理架构，其核心对接逻辑如下：

```
┌─────────────────────────────────────────────────────────────────────┐
│                     Vercel AI SDK 流式架构                          │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  前端层                     API层                    后端服务层      │
│  ┌─────────────┐           ┌─────────────┐         ┌────────────┐ │
│  │ useChat()   │ ────────► │ /chat/route │ ──────► │ LLM 模型   │ │
│  │ 流式hook    │  SSE流    │ POST处理器  │ streamText() │         │ │
│  └─────────────┘           └─────────────┘         └────────────┘ │
│        ▲                        │                        │         │
│        │                        ▼                        ▼         │
│  ┌─────────────┐         ┌─────────────┐         ┌────────────┐ │
│  │ Message     │         │ StreamText  │         │ OpenAI兼容 │ │
│  │ Stream组件  │         │ Response    │         │ Provider   │ │
│  └─────────────┘         └─────────────┘         └────────────┘ │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

#### 核心代码实现 ([`app/api/local-aibot/chat/route.ts`](app/api/local-aibot/chat/route.ts:247-255))

```typescript
// 第247-255行：使用 streamText 发起流式请求
const result = streamText({
    model: createModel(workflowContext.llmConfig),  // 创建模型实例
    system: workflowContext.systemPrompt,            // 系统提示词
    messages: chatMessages as any
});

// 返回流式响应
return result.toTextStreamResponse({
    headers: streamHeadersWithRetrieval(classification, workflowContext.mode, workflowContext.retrievalResultData)
});
```

#### 模型创建逻辑 ([`src/core/aibot/researchWorkflow.ts`](src/core/aibot/researchWorkflow.ts:13-27))

```typescript
const createModel = (config: LLMConfig) => {
    const customProvider = createOpenAICompatible({
        name: 'custom-llm',
        baseURL: config.baseURL,  // LLM基础URL
        apiKey: config.apiKey
    });
    
    return customProvider(config.model);  // 返回模型实例
};
```

**技术对接要点**：
1. **Provider 模式**：通过 `createOpenAICompatible` 创建自定义 Provider，适配任意 OpenAI 兼容的 LLM API
2. **流式响应**：`streamText()` 返回可迭代流，通过 `toTextStreamResponse()` 转换为 HTTP SSE 流
3. **上下文传递**：系统提示词（system prompt）与用户消息分离构建，确保对话连贯性

---

### 1.2 意图分类器所属层级与路由机制

意图分类器位于 **API 路由层**，是请求进入业务逻辑前的"门禁"：

```
┌─────────────────────────────────────────────────────────────────┐
│                      请求路由决策流程                            │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  用户请求 ──► API路由层 ──► 意图分类器 ──► 业务处理             │
│                        │                                         │
│                        ▼                                         │
│               ┌─────────────────┐                                │
│               │ classify/route  │ ◄─── 意图分类器位置           │
│               │                  │                               │
│               │ 输入: 用户消息   │                               │
│               │ 输出: intent类型 │                               │
│               └─────────────────┘                                │
│                        │                                         │
│         ┌──────────────┼──────────────┐                         │
│         ▼              ▼              ▼                         │
│   ┌──────────┐  ┌──────────┐  ┌──────────┐                     │
│   │ SEARCH   │  │   OTHER  │  │ 继续词   │                     │
│   │ 简单检索 │  │ 友好提示 │  │ 跳过分类 │                     │
│   └──────────┘  └──────────┘  └──────────┘                     │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

#### 意图分类实现 ([`app/api/local-aibot/classify/route.ts`](app/api/local-aibot/classify/route.ts:37-49))

```typescript
// 第37-49行：调用分类器
const classification = await classifyUserIntent({
    userInput: userInput.trim(),
    messages
});

return NextResponse.json(classification);
```

#### 分类器核心逻辑 ([`src/core/aibot/classifier.ts`](src/core/aibot/classifier.ts:112-147))

```typescript
export async function classifyUserIntent(input: IntentClassifierInput): Promise<IntentClassificationResult> {
    const prompt = await loadPrompt(AIBOT_PROMPT_FILES.QUESTION_CLASSIFIER);
    const llmConfig = resolveLLMConfig(undefined, {
        model: 'gemini-flash-latest',  // 使用轻量模型加速分类
        temperature: 0                  // 确定性输出
    });
    
    const result = await generateText({
        model,
        system: prompt,
        prompt: buildClassifierPrompt({ ...input, userInput: trimmed })
    });

    return parseClassifierText(result.text);
}
```

#### 意图类型定义 ([`src/core/aibot/constants.ts`](src/core/aibot/constants.ts))

```typescript
// 意图类型映射
const AIBOT_INTENTS = {
    SEARCH: 'simple_search',      // 简单检索
    DEEP: 'deep_search',          // 深度检索（需识别特定模式）
    DOCUMENT: 'document_analysis', // 文档分析
    OTHER: 'other'                // 非检索任务
} as const;
```

**路由引导机制**：
1. **意图分类**：LLM 分析用户输入，判断其属于检索类还是闲聊类
2. **模式路由**：`determineMode()` 函数根据分类结果和请求参数决定处理模式
3. **降级策略**：当检测到草稿内容时，自动降级到深度检索模式

---

## 二、全链路数据闭环

### 2.1 人在环交互（Human-in-the-loop）实现

人在环交互是 AIBot 的核心创新点，允许用户在 AI 决策过程中介入、编辑和确认：

```
┌─────────────────────────────────────────────────────────────────────┐
│                    人在环交互工作流程                                │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  阶段1: 分析生成        阶段2: 草稿展示        阶段3: 用户确认        │
│  ┌──────────────┐      ┌──────────────┐      ┌──────────────┐      │
│  │ AI自动生成   │ ───► │ 可视化展示   │ ───► │ 用户编辑     │      │
│  │ 关键词/检索  │      │ 支持编辑     │      │ 确认/修改    │      │
│  └──────────────┘      └──────────────┘      └──────────────┘      │
│         │                     │                     │               │
│         ▼                     ▼                     ▼               │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │                    DraftConfirmationDisplay                  │   │
│  │  ┌─────────────────────────────────────────────────────┐    │   │
│  │  │  textarea 编辑器 (第200-205行)                       │    │   │
│  │  │  onChange={(e) => setEditValue(e.target.value)}     │    │   │
│  │  └─────────────────────────────────────────────────────┘    │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

#### 草稿确认组件 ([`components/aibot/DraftConfirmationDisplay.tsx`](components/aibot/DraftConfirmationDisplay.tsx))

```typescript
// 第51-64行：编辑功能实现
const handleStartEdit = () => {
    setEditValue(cleanedDraft);  // 加载当前草稿到编辑区
    setIsEditing(true);
};

const handleSaveEdit = () => {
    onDraftChange(editValue);    // 保存用户编辑后的草稿
    setIsEditing(false);
};
```

#### 草稿重新进入深度检索 ([`components/aibot/DeepSearchWorkflow.tsx`](components/aibot/DeepSearchWorkflow.tsx:209-277))

```typescript
// 第209-277行：确认后执行图书检索
const handleDraftConfirmAndSearch = async () => {
    // 用户确认后，使用编辑后的草稿进行检索
    const response = await fetch('/api/local-aibot/deep-search', {
        method: 'POST',
        body: JSON.stringify({
            draftMarkdown,          // 传递用户编辑后的草稿
            userInput
        })
    });
};
```

#### 后端接收编辑后的草稿 ([`app/api/local-aibot/deep-search/route.ts`](app/api/local-aibot/deep-search/route.ts:41-47))

```typescript
// 第41-47行：基于草稿进行图书检索
const retrieval = await multiQuery({
    markdown_text: draftMarkdown,  // 使用用户确认/编辑的草稿
    per_query_top_k: 8,
    final_top_k: 12,
    enable_rerank: true
});
```

**人在环交互的关键机制**：
1. **草稿展示与编辑**：用户提供可编辑的草稿界面，支持实时修改
2. **状态同步**：用户编辑后通过 `onDraftChange()` 更新父组件状态
3. **二次检索触发**：确认后，编辑后的草稿重新进入 `multiQuery()` 进行图书检索
4. **透明度展示**：支持查看源数据（searchSnippets），确保用户了解 AI 判断依据

---

### 2.2 Markdown 文档解析与上下文转化

当用户上传 Markdown 文档时，系统将其解析并转化为 Agent 可读取的上下文：

```
┌─────────────────────────────────────────────────────────────────────┐
│                   Markdown 文档解析流程                              │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  用户上传              文件读取              内容解析                │
│  ┌──────────┐        ┌──────────┐        ┌──────────┐              │
│  │ File API │ ─────► │ file.text │ ─────► │ 字符串   │              │
│  │          │        │ ()        │        │ content  │              │
│  └──────────┘        └──────────┘        └──────────┘              │
│                                                   │                 │
│                                                   ▼                 │
│  ┌─────────────────────────────────────────────────────────────────┐
│  │                      DocumentUploadWorkflow                      │
│  │  第35-50行：文件读取与状态管理                                   │
│  │                                                                 │
│  │  const handleFilesSelected = async (files: File[]) => {         │
│  │      for (const file of files) {                                │
│  │          const content = await file.text();  // 读取Markdown    │
│  │          addUploadedDocument({                                   │
│  │              id: crypto.randomUUID(),                            │
│  │              name: file.name,                                    │
│  │              content,         // 原始Markdown内容               │
│  │              status: 'ready'                                     │
│  │          });                                                    │
│  │      }                                                          │
│  │  };                                                             │
│  └─────────────────────────────────────────────────────────────────┘
│                                                   │                 │
│                                                   ▼                 │
│  ┌─────────────────────────────────────────────────────────────────┐
│  │                   document-analysis/route.ts                     │
│  │  第88-127行：并行文档分析                                        │
│  │                                                                 │
│  │  const analysisPromises = documents.map(async (document) => {   │
│  │      const articlePrompt = await loadPrompt(...);               │
│  │      const analysisResult = await generateText({               │
│  │          model,                                                 │
│  │          system: articlePrompt,                                 │
│  │          prompt: `# 文档名称\n${document.name}\n\n             │
│  │                    # 文档内容\n${document.content}`             │
│  │      });                                                       │
│  │  });                                                           │
│  └─────────────────────────────────────────────────────────────────┘
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

#### 文档分析 API ([`app/api/local-aibot/document-analysis/route.ts`](app/api/local-aibot/document-analysis/route.ts))

```typescript
// 第89-127行：并行分析所有文档
const analysisPromises = documents.map(async (document, index) => {
    const articlePrompt = await loadPrompt(AIBOT_PROMPT_FILES.ARTICLE_ANALYSIS);
    
    const analysisResult = await generateText({
        model,
        system: articlePrompt,
        prompt: `# 文档名称\n${document.name}\n\n# 文档内容\n${document.content}`
    });

    return { analysis: analysisResult.text.trim(), documentName: document.name };
});

// 等待所有分析完成
const analysisResults = await Promise.all(analysisPromises);
```

#### 交叉分析生成上下文 ([`app/api/local-aibot/document-analysis/route.ts`](app/api/local-aibot/document-analysis/route.ts:149-169))

```typescript
// 第149-169行：交叉分析，生成统一草稿
const combinedAnalyses = documentAnalyses.join('\n\n---\n\n');
const crossPrompt = await loadPrompt(AIBOT_PROMPT_FILES.ARTICLE_CROSS_ANALYSIS);

const crossAnalysisStream = await streamText({
    model,
    system: crossPrompt,
    prompt: `# 文档名称\n${documentNames}\n\n# 文档分析结果\n${combinedAnalyses}`
});
```

**文档到上下文的转化链**：
1. **文件读取**：使用浏览器 File API 读取 Markdown 原始文本
2. **内容存储**：以字符串形式存储在 `UploadedDocument.content` 中
3. **单篇分析**：每篇文档独立调用 LLM 进行 `article_analysis` 提示词处理
4. **交叉整合**：将多篇分析结果合并，调用 `article_cross_analysis` 生成综合草稿
5. **检索输入**：最终草稿作为 `multiQuery()` 的输入，执行图书检索

---

## 三、技术路径选型理由

### 3.1 六阶段完整流程的精准度保障

深度检索采用 **6 阶段完整流程**，每阶段都有明确的质量保障机制：

```
┌─────────────────────────────────────────────────────────────────────────┐
│                      深度检索六阶段流程                                  │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  阶段1           阶段2           阶段3           阶段4    阶段5  阶段6  │
│  关键词生成  ─►  网络搜索    ─►  单篇分析    ─►  交叉分析 ─► 检索 ─► 解读│
│                                                                         │
│  ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐ ┌──────┐ ┌────┐│
│  │ Gemini  │   │ Jina/   │   │ Gemini  │   │ Gemini  │ │向量库│ │流式││
│  │ Flash   │   │ DDG     │   │ Flash   │   │ Flash   │ │检索 │ │输出││
│  │ 轻量模型│   │ 搜索    │   │ 轻量模型│   │ 轻量模型│ │     │ │   ││
│  └─────────┘   └─────────┘   └─────────┘   └─────────┘ └──────┘ └────┘│
│       │             │             │             │           │       │   │
│       ▼             ▼             ▼             ▼           ▼       ▼   │
│  ┌─────────────────────────────────────────────────────────────────────┐│
│  │  代码实现：deep-search-analysis/route.ts 第93-254行                   ││
│  └─────────────────────────────────────────────────────────────────────┘│
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

#### 六阶段代码详解

```typescript
// 阶段1：关键词生成 (第93-142行)
const keywordPrompt = await loadPrompt(AIBOT_PROMPT_FILES.KEYWORD_GENERATION);
const keywordResult = await generateText({
    model,
    system: keywordPrompt,
    prompt: `用户输入：${userInput}\n\n请生成适合的检索关键词。`
});
// 生成带优先级的高/中/低关键词列表

// 阶段2：网络搜索 (第159-170行)
const snippets = await performWebSearch(keywordItem.keyword);
// 支持 Jina/DuckDuckGo 并行检索

// 阶段3：单篇分析 (第173-189行)
const articlePrompt = await loadPrompt(AIBOT_PROMPT_FILES.ARTICLE_ANALYSIS);
const analysisResult = await generateText({
    model,
    system: articlePrompt,
    prompt: `# 关键词\n${keywordItem.keyword}\n\n# 网络搜索结果\n${searchResultText}`
});
// 提取每篇文章的核心观点

// 阶段4：交叉分析 (第212-253行)
const crossPrompt = await loadPrompt(AIBOT_PROMPT_FILES.ARTICLE_CROSS_ANALYSIS);
// 使用 streamText 流式输出综合草稿
const crossAnalysisStream = await streamText({
    model,
    system: crossPrompt,
    prompt: `...合并所有分析结果...`
});

// 阶段5：图书检索 (第42-47行)
const retrieval = await multiQuery({
    markdown_text: draftMarkdown,
    per_query_top_k: 8,
    final_top_k: 12,
    enable_rerank: true  // 启用重排序提升精度
});

// 阶段6：解读生成 (deep-interpretation/route.ts)
const result = streamText({
    model,
    system: recommendationPrompt,
    prompt: fullPrompt
});
```

**六阶段流程的精准度保障**：

| 阶段 | 技术选型 | 精度保障机制 |
|------|---------|-------------|
| 关键词生成 | 轻量模型 | 生成带优先级的关键词列表，避免单一关键词遗漏 |
| 网络搜索 | Jina/DDG | 多搜索引擎并行，覆盖不同数据源 |
| 单篇分析 | 轻量模型 | 每篇文章独立分析，提取结构化信息 |
| 交叉分析 | 轻量模型 | 多角度综合，生成检索草稿 |
| 图书检索 | 向量库+重排序 | `multiQuery` 多查询融合 + `rerank` 优化排序 |
| 解读生成 | 流式输出 | 基于检索结果生成个性化推荐 |

---

### 3.2 Server-Sent Events (SSE) 流式推送技术优势

SSE 实现了长文本的分段推送和实时展示，是流式体验的技术基础：

```
┌─────────────────────────────────────────────────────────────────────────┐
│                         SSE 流式推送架构                                 │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  后端 (ReadableStream)              前端 (SSE Consumer)                 │
│  ┌────────────────────┐            ┌────────────────────┐               │
│  │ TextEncoder        │            │ response.body      │               │
│  │ 编码器             │            │ .getReader()       │               │
│  └─────────┬──────────┘            └─────────┬──────────┘               │
│            │                                │                           │
│            │  data: {...}\n\n              │  read() 迭代               │
│            │  data: {...}\n\n              │                           │
│            ▼                                ▼                           │
│  ┌─────────────────────────────────────────────────────────────────┐   │
│  │                    sendProgress() 实现                          │   │
│  │  第17-30行：SSE 事件构建与推送                                   │   │
│  │                                                                 │   │
│  │  const sendProgress = (controller, phase, message, status) => { │   │
│  │      const progressData = {                                      │   │
│  │          type: 'progress',                                       │   │
│  │          phase,                                                  │   │
│  │          message,                                                │   │
│  │          status,                                                 │   │
│  │          timestamp: new Date().toISOString()                     │   │
│  │      };                                                          │   │
│  │      const data = `data: ${JSON.stringify(progressData)}\n\n`;  │   │
│  │      controller.enqueue(new TextEncoder().encode(data));         │   │
│  │  };                                                              │   │
│  └─────────────────────────────────────────────────────────────────┘   │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

#### 草稿流式推送 ([`app/api/local-aibot/deep-search-analysis/route.ts`](app/api/local-aibot/deep-search-analysis/route.ts:227-244))

```typescript
// 第227-244行：流式输出草稿内容
const crossAnalysisStream = await streamText({
    model,
    system: crossPrompt,
    prompt: `...`
});

let draftMarkdown = '';

// 逐块流式输出草稿内容
for await (const chunk of crossAnalysisStream.textStream) {
    draftMarkdown += chunk;
    const draftChunkData = {
        type: 'draft-chunk',
        content: chunk  // 单个文本块
    };
    controller.enqueue(encoder.encode(`data: ${JSON.stringify(draftChunkData)}\n\n`));
}
```

#### 前端流式接收 ([`components/aibot/DeepSearchWorkflow.tsx`](components/aibot/DeepSearchWorkflow.tsx:143-193))

```typescript
// 第143-193行：SSE 流式读取与处理
const reader = response.body?.getReader();
const decoder = new TextDecoder();

while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    
    buffer += decoder.decode(value, { stream: true });
    const lines = buffer.split('\n');
    buffer = lines.pop() || '';
    
    for (const line of lines) {
        if (line.startsWith('data: ')) {
            const data = JSON.parse(line.slice(6));
            
            if (data.type === 'progress') {
                // 更新进度日志
                addLog({ phase: data.phase, ... });
            } else if (data.type === 'draft-chunk') {
                // 累积草稿内容
                setDraftMarkdown(prev => prev + data.content);
            } else if (data.type === 'draft-complete') {
                // 草稿完成
                processFinalResult(data);
            }
        }
    }
}
```

**SSE 技术优势在代码中的体现**：

| 优势 | 代码实现 | 用户体验价值 |
|------|---------|-------------|
| **实时性** | `controller.enqueue()` 立即推送 | 用户无需等待完整生成即可看到内容 |
| **分段展示** | `draft-chunk` 事件逐块发送 | 长文本逐字/逐句显示，无白屏等待 |
| **进度反馈** | `progress` 事件报告阶段状态 | 用户了解当前处理环节（如"正在进行交叉分析..."） |
| **错误恢复** | `error` 事件支持错误提示 | 出错时可及时告知用户 |
| **连接保持** | `Content-Type: text/event-stream` | 单HTTP连接复用，减少服务器负载 |

#### SSE 响应头配置 ([`app/api/local-aibot/deep-search-analysis/route.ts`](app/api/local-aibot/deep-search-analysis/route.ts:275-280))

```typescript
return new Response(stream, {
    headers: {
        'Content-Type': 'text/event-stream',       // SSE 声明
        'Cache-Control': 'no-cache',               // 禁用缓存
        'Connection': 'keep-alive',                // 保持连接
    },
});
```

---

## 四、总结

### 技术架构要点

1. **三层架构映射**：
   - Vercel AI SDK 封装底层 LLM 调用，统一接口
   - 意图分类器位于 API 层，作为请求路由的"门禁"
   - 工作流管理解耦不同检索模式的处理逻辑

2. **人在环交互**：
   - 草稿确认组件提供可视化编辑界面
   - 用户编辑后可触发二次检索，实现"AI 建议 + 人工修正"
   - 源数据透明展示，增强用户信任

3. **六阶段精准检索**：
   - 关键词 → 搜索 → 分析 → 交叉 → 检索 → 解读
   - 每阶段独立质量控制，融合多源数据
   - `multiQuery` + `rerank` 保障检索精度

4. **SSE 流式推送**：
   - 长文本分段传输，用户实时感知生成进度
   - `draft-chunk` 事件实现逐字流式渲染
   - `progress` 事件提供多阶段状态反馈
